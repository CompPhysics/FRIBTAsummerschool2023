<!--
HTML file automatically generated from DocOnce source
(https://github.com/doconce/doconce/)
doconce format html mlnuclear.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=mlnuclear-bs --no_mako
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/doconce/doconce/" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta name="description" content="Practical Uncertainty Quantification and Emulator Development in Nuclear Physics">
<title>Practical Uncertainty Quantification and Emulator Development in Nuclear Physics</title>
<!-- Bootstrap style: bootstrap -->
<!-- doconce format html mlnuclear.do.txt --html_style=bootstrap --pygments_html_style=default --html_admon=bootstrap_panel --html_output=mlnuclear-bs --no_mako -->
<link href="https://netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->
<style type="text/css">
/* Add scrollbar to dropdown menus in bootstrap navigation bar */
.dropdown-menu {
   height: auto;
   max-height: 400px;
   overflow-x: hidden;
}
/* Adds an invisible element before each target to offset for the navigation
   bar */
.anchor::before {
  content:"";
  display:block;
  height:50px;      /* fixed header height for style bootstrap */
  margin:-50px 0 0; /* negative fixed header height */
}
</style>
</head>

<!-- tocinfo
{'highest level': 1,
 'sections': [('What is this lecture about?',
               2,
               None,
               'what-is-this-lecture-about'),
              ('Many folks to thank', 2, None, 'many-folks-to-thank'),
              ('A simple perspective on the interface between ML and Physics',
               2,
               None,
               'a-simple-perspective-on-the-interface-between-ml-and-physics'),
              ('What is Machine Learning?',
               2,
               None,
               'what-is-machine-learning'),
              ('Popular libraries', 2, None, 'popular-libraries'),
              ('Types of Machine Learning',
               2,
               None,
               'types-of-machine-learning'),
              ('Essential elements of ML', 2, None, 'essential-elements-of-ml'),
              ('An optimization/minimization problem',
               2,
               None,
               'an-optimization-minimization-problem'),
              ('A Frequentist approach to data analysis',
               2,
               None,
               'a-frequentist-approach-to-data-analysis'),
              ('What is a good model?', 2, None, 'what-is-a-good-model'),
              ('What is a good model? Can we define it?',
               2,
               None,
               'what-is-a-good-model-can-we-define-it'),
              ('ML in Nuclear  Physics', 2, None, 'ml-in-nuclear-physics'),
              ('AI/ML and some statements you may have heard (and what do they '
               'mean?)',
               2,
               None,
               'ai-ml-and-some-statements-you-may-have-heard-and-what-do-they-mean'),
              ('Scientific Machine Learning',
               2,
               None,
               'scientific-machine-learning'),
              ('Machine Learning and Physics',
               2,
               None,
               'machine-learning-and-physics'),
              ('Lots of room for creativity',
               2,
               None,
               'lots-of-room-for-creativity'),
              ('Machine learning and nuclear theory: Why?',
               2,
               None,
               'machine-learning-and-nuclear-theory-why'),
              ('The plethora  of machine learning algorithms/methods',
               2,
               None,
               'the-plethora-of-machine-learning-algorithms-methods'),
              ('Examples of Machine Learning methods and applications in '
               'nuclear physics',
               2,
               None,
               'examples-of-machine-learning-methods-and-applications-in-nuclear-physics'),
              ('Examples of Machine Learning methods and applications in '
               'nuclear physics, continues',
               2,
               None,
               'examples-of-machine-learning-methods-and-applications-in-nuclear-physics-continues'),
              ('More examples', 2, None, 'more-examples'),
              ('And more', 2, None, 'and-more'),
              ('Selected references', 2, None, 'selected-references'),
              ('"Unsupervised learning in nuclear physics, Argon-46 by Solli, '
               'Bazin, Kuchera, MHJ, '
               'Strauss.":"https://www.sciencedirect.com/science/article/abs/pii/S0168900221004460?via%3Dihub"',
               2,
               None,
               'unsupervised-learning-in-nuclear-physics-argon-46-by-solli-bazin-kuchera-mhj-strauss-https-www-sciencedirect-com-science-article-abs-pii-s0168900221004460-via-3dihub'),
              ('Quantum Monte Carlo and deep learning',
               2,
               None,
               'quantum-monte-carlo-and-deep-learning'),
              ('Monte Carlo methods and Neural Networks',
               2,
               None,
               'monte-carlo-methods-and-neural-networks'),
              ('Deep learning neural networks, "Variational Monte Carlo '
               'calculations of $A\\le 4$ nuclei with an artificial '
               'neural-network correlator ansatz by Adams et '
               'al.":"https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.127.022502"',
               2,
               None,
               'deep-learning-neural-networks-variational-monte-carlo-calculations-of-a-le-4-nuclei-with-an-artificial-neural-network-correlator-ansatz-by-adams-et-al-https-journals-aps-org-prl-abstract-10-1103-physrevlett-127-022502'),
              ('"Gnech et al, Variational Monte Carlo calculations of $A\\le '
               '6$ nuclei Few Body Systems 63, '
               '(2022)":"https://link.springer.com/article/10.1007/s00601-021-01706-0"',
               2,
               None,
               'gnech-et-al-variational-monte-carlo-calculations-of-a-le-6-nuclei-few-body-systems-63-2022-https-link-springer-com-article-10-1007-s00601-021-01706-0'),
              ('The electron gas in three dimensions with $N=14$ electrons '
               '(Wigner-Seitz radius $r_s=2$ Ry)',
               2,
               None,
               'the-electron-gas-in-three-dimensions-with-n-14-electrons-wigner-seitz-radius-r-s-2-ry'),
              ('Neutron matter with $N=14$ neutron',
               2,
               None,
               'neutron-matter-with-n-14-neutron'),
              ('Electrons in a harmonic oscillator trap in two dimensions',
               2,
               None,
               'electrons-in-a-harmonic-oscillator-trap-in-two-dimensions'),
              ('Quantum dots and Boltzmann machines, onebody densities $N=6$, '
               '$\\hbar\\omega=0.1$ a.u.',
               2,
               None,
               'quantum-dots-and-boltzmann-machines-onebody-densities-n-6-hbar-omega-0-1-a-u'),
              ('Onebody densities $N=30$, $\\hbar\\omega=1.0$ a.u.',
               2,
               None,
               'onebody-densities-n-30-hbar-omega-1-0-a-u'),
              ('Onebody densities $N=30$, $\\hbar\\omega=0.1$ a.u.',
               2,
               None,
               'onebody-densities-n-30-hbar-omega-0-1-a-u'),
              ('Extrapolations and model interpretability',
               2,
               None,
               'extrapolations-and-model-interpretability'),
              ('Physics based statistical learning and data analysis',
               2,
               None,
               'physics-based-statistical-learning-and-data-analysis'),
              ("Bayes' Theorem", 2, None, 'bayes-theorem'),
              ('Quantified limits of the nuclear landscape',
               2,
               None,
               'quantified-limits-of-the-nuclear-landscape'),
              ('Constraining the equation of state for dense nuclear matter',
               2,
               None,
               'constraining-the-equation-of-state-for-dense-nuclear-matter'),
              ('Observations (or conclusions if you prefer)',
               2,
               None,
               'observations-or-conclusions-if-you-prefer'),
              ('Possible start to raise awareness about ML in our field',
               2,
               None,
               'possible-start-to-raise-awareness-about-ml-in-our-field'),
              ('To our real data: nuclear binding energies. Brief reminder on '
               'masses and binding energies',
               3,
               None,
               'to-our-real-data-nuclear-binding-energies-brief-reminder-on-masses-and-binding-energies'),
              ('Organizing our data', 3, None, 'organizing-our-data'),
              ('Seeing the wood for the trees',
               3,
               None,
               'seeing-the-wood-for-the-trees'),
              ('And what about using neural networks?',
               3,
               None,
               'and-what-about-using-neural-networks'),
              ('Background material', 1, None, 'background-material'),
              ('Why Linear Regression (aka Ordinary Least Squares and family)',
               2,
               None,
               'why-linear-regression-aka-ordinary-least-squares-and-family'),
              ('Regression analysis, overarching aims',
               2,
               None,
               'regression-analysis-overarching-aims'),
              ('Regression analysis, overarching aims II',
               2,
               None,
               'regression-analysis-overarching-aims-ii'),
              ('Examples', 2, None, 'examples'),
              ('General linear models', 2, None, 'general-linear-models'),
              ('Rewriting the fitting procedure as a linear algebra problem',
               2,
               None,
               'rewriting-the-fitting-procedure-as-a-linear-algebra-problem'),
              ('Rewriting the fitting procedure as a linear algebra problem, '
               'more details',
               2,
               None,
               'rewriting-the-fitting-procedure-as-a-linear-algebra-problem-more-details'),
              ('Generalizing the fitting procedure as a linear algebra problem',
               2,
               None,
               'generalizing-the-fitting-procedure-as-a-linear-algebra-problem'),
              ('Generalizing the fitting procedure as a linear algebra problem',
               2,
               None,
               'generalizing-the-fitting-procedure-as-a-linear-algebra-problem'),
              ('Optimizing our parameters',
               2,
               None,
               'optimizing-our-parameters'),
              ('Our model for the nuclear binding energies',
               2,
               None,
               'our-model-for-the-nuclear-binding-energies'),
              ('Optimizing our parameters, more details',
               2,
               None,
               'optimizing-our-parameters-more-details'),
              ('Interpretations and optimizing our parameters',
               2,
               None,
               'interpretations-and-optimizing-our-parameters'),
              ('Interpretations and optimizing our parameters',
               2,
               None,
               'interpretations-and-optimizing-our-parameters'),
              ('Some useful matrix and vector expressions',
               2,
               None,
               'some-useful-matrix-and-vector-expressions'),
              ('Interpretations and optimizing our parameters',
               2,
               None,
               'interpretations-and-optimizing-our-parameters'),
              ('Own code for Ordinary Least Squares',
               2,
               None,
               'own-code-for-ordinary-least-squares'),
              ('Adding error analysis and training set up',
               2,
               None,
               'adding-error-analysis-and-training-set-up'),
              ('The $\\chi^2$ function', 2, None, 'the-chi-2-function'),
              ('The $\\chi^2$ function', 2, None, 'the-chi-2-function'),
              ('The $\\chi^2$ function', 2, None, 'the-chi-2-function'),
              ('The $\\chi^2$ function', 2, None, 'the-chi-2-function'),
              ('The $\\chi^2$ function', 2, None, 'the-chi-2-function'),
              ('The $\\chi^2$ function', 2, None, 'the-chi-2-function'),
              ('Why Linear Regression (aka Ordinary Least Squares and family), '
               'repeat from last week',
               2,
               None,
               'why-linear-regression-aka-ordinary-least-squares-and-family-repeat-from-last-week'),
              ('Regression analysis, overarching aims',
               2,
               None,
               'regression-analysis-overarching-aims'),
              ('Regression analysis, overarching aims II',
               2,
               None,
               'regression-analysis-overarching-aims-ii'),
              ('Examples', 2, None, 'examples'),
              ('General linear models', 2, None, 'general-linear-models'),
              ('Rewriting the fitting procedure as a linear algebra problem',
               2,
               None,
               'rewriting-the-fitting-procedure-as-a-linear-algebra-problem'),
              ('Rewriting the fitting procedure as a linear algebra problem, '
               'more details',
               2,
               None,
               'rewriting-the-fitting-procedure-as-a-linear-algebra-problem-more-details'),
              ('Generalizing the fitting procedure as a linear algebra problem',
               2,
               None,
               'generalizing-the-fitting-procedure-as-a-linear-algebra-problem'),
              ('Generalizing the fitting procedure as a linear algebra problem',
               2,
               None,
               'generalizing-the-fitting-procedure-as-a-linear-algebra-problem'),
              ('Optimizing our parameters',
               2,
               None,
               'optimizing-our-parameters'),
              ('Our model for the nuclear binding energies',
               2,
               None,
               'our-model-for-the-nuclear-binding-energies'),
              ('Optimizing our parameters, more details',
               2,
               None,
               'optimizing-our-parameters-more-details'),
              ('Interpretations and optimizing our parameters',
               2,
               None,
               'interpretations-and-optimizing-our-parameters'),
              ('Interpretations and optimizing our parameters',
               2,
               None,
               'interpretations-and-optimizing-our-parameters'),
              ('Some useful matrix and vector expressions',
               2,
               None,
               'some-useful-matrix-and-vector-expressions'),
              ('Meet the Hessian Matrix', 2, None, 'meet-the-hessian-matrix'),
              ('Interpretations and optimizing our parameters',
               2,
               None,
               'interpretations-and-optimizing-our-parameters'),
              ('Own code for Ordinary Least Squares',
               2,
               None,
               'own-code-for-ordinary-least-squares'),
              ('Adding error analysis and training set up',
               2,
               None,
               'adding-error-analysis-and-training-set-up'),
              ('Splitting our Data in Training and Test data',
               2,
               None,
               'splitting-our-data-in-training-and-test-data'),
              ('Examples', 2, None, 'examples'),
              ('Making your own test-train splitting',
               2,
               None,
               'making-your-own-test-train-splitting'),
              ('The Boston housing data example',
               2,
               None,
               'the-boston-housing-data-example'),
              ('Housing data, the code', 2, None, 'housing-data-the-code'),
              ('Reducing the number of degrees of freedom, overarching view',
               2,
               None,
               'reducing-the-number-of-degrees-of-freedom-overarching-view'),
              ('Preprocessing our data', 2, None, 'preprocessing-our-data'),
              ('Functionality in Scikit-Learn',
               2,
               None,
               'functionality-in-scikit-learn'),
              ('More preprocessing', 2, None, 'more-preprocessing'),
              ('Frequently used scaling functions',
               2,
               None,
               'frequently-used-scaling-functions'),
              ('Example of own Standard scaling',
               2,
               None,
               'example-of-own-standard-scaling'),
              ('Min-Max Scaling', 2, None, 'min-max-scaling'),
              ('Testing the Means Squared Error as function of Complexity',
               2,
               None,
               'testing-the-means-squared-error-as-function-of-complexity'),
              ('More preprocessing examples, Franke function and regression',
               2,
               None,
               'more-preprocessing-examples-franke-function-and-regression'),
              ('Mathematical Interpretation of Ordinary Least Squares',
               2,
               None,
               'mathematical-interpretation-of-ordinary-least-squares'),
              ('Residual Error', 2, None, 'residual-error'),
              ('Simple case', 2, None, 'simple-case'),
              ('The singular value decomposition',
               2,
               None,
               'the-singular-value-decomposition'),
              ('Linear Regression Problems',
               2,
               None,
               'linear-regression-problems'),
              ('Fixing the singularity', 2, None, 'fixing-the-singularity'),
              ('Basic math of the SVD', 2, None, 'basic-math-of-the-svd'),
              ('The SVD, a Fantastic Algorithm',
               2,
               None,
               'the-svd-a-fantastic-algorithm'),
              ('Economy-size SVD', 2, None, 'economy-size-svd'),
              ('Codes for the SVD', 2, None, 'codes-for-the-svd'),
              ('Note about SVD Calculations',
               2,
               None,
               'note-about-svd-calculations'),
              ('Mathematics of the SVD and implications',
               2,
               None,
               'mathematics-of-the-svd-and-implications'),
              ('Example Matrix', 2, None, 'example-matrix'),
              ('Setting up the Matrix to be inverted',
               2,
               None,
               'setting-up-the-matrix-to-be-inverted'),
              ('Further properties (important for our analyses later)',
               2,
               None,
               'further-properties-important-for-our-analyses-later'),
              ('Meet the Covariance Matrix',
               2,
               None,
               'meet-the-covariance-matrix'),
              ('Introducing the Covariance and Correlation functions',
               2,
               None,
               'introducing-the-covariance-and-correlation-functions'),
              ('Covariance and Correlation Matrix',
               2,
               None,
               'covariance-and-correlation-matrix'),
              ('Correlation Function and Design/Feature Matrix',
               2,
               None,
               'correlation-function-and-design-feature-matrix'),
              ('Covariance Matrix Examples',
               2,
               None,
               'covariance-matrix-examples'),
              ('Correlation Matrix', 2, None, 'correlation-matrix'),
              ('Correlation Matrix with Pandas',
               2,
               None,
               'correlation-matrix-with-pandas'),
              ('Correlation Matrix with Pandas and the Franke function',
               2,
               None,
               'correlation-matrix-with-pandas-and-the-franke-function'),
              ('Rewriting the Covariance and/or Correlation Matrix',
               2,
               None,
               'rewriting-the-covariance-and-or-correlation-matrix'),
              ('Linking with the SVD', 2, None, 'linking-with-the-svd'),
              ('What does it mean?', 2, None, 'what-does-it-mean'),
              ('And finally  $\\boldsymbol{X}\\boldsymbol{X}^T$',
               2,
               None,
               'and-finally-boldsymbol-x-boldsymbol-x-t'),
              ('Ridge and LASSO Regression',
               2,
               None,
               'ridge-and-lasso-regression'),
              ('Deriving the  Ridge Regression Equations',
               2,
               None,
               'deriving-the-ridge-regression-equations'),
              ('Interpreting the Ridge results',
               2,
               None,
               'interpreting-the-ridge-results'),
              ('More interpretations', 2, None, 'more-interpretations'),
              ('Deriving the  Lasso Regression Equations',
               2,
               None,
               'deriving-the-lasso-regression-equations'),
              ('Exercises for week 35', 2, None, 'exercises-for-week-35'),
              ('Exercise 1: Setting up various Python environments',
               2,
               None,
               'exercise-1-setting-up-various-python-environments'),
              ('Linear Regression and  the SVD',
               2,
               None,
               'linear-regression-and-the-svd'),
              ('What does it mean?', 2, None, 'what-does-it-mean'),
              ('And finally  $\\boldsymbol{X}\\boldsymbol{X}^T$',
               2,
               None,
               'and-finally-boldsymbol-x-boldsymbol-x-t'),
              ('Code for SVD and Inversion of Matrices',
               2,
               None,
               'code-for-svd-and-inversion-of-matrices'),
              ('Inverse of Rectangular Matrix',
               2,
               None,
               'inverse-of-rectangular-matrix'),
              ('Ridge and LASSO Regression',
               2,
               None,
               'ridge-and-lasso-regression'),
              ('From OLS to Ridge and Lasso',
               2,
               None,
               'from-ols-to-ridge-and-lasso'),
              ('Deriving the  Ridge Regression Equations',
               2,
               None,
               'deriving-the-ridge-regression-equations'),
              ('Note on Scikit-Learn', 2, None, 'note-on-scikit-learn'),
              ('Comparison with OLS', 2, None, 'comparison-with-ols'),
              ('SVD analysis', 2, None, 'svd-analysis'),
              ('Interpreting the Ridge results',
               2,
               None,
               'interpreting-the-ridge-results'),
              ('More interpretations', 2, None, 'more-interpretations'),
              ('Deriving the  Lasso Regression Equations',
               2,
               None,
               'deriving-the-lasso-regression-equations'),
              ('Simple example to illustrate Ordinary Least Squares, Ridge and '
               'Lasso Regression',
               2,
               None,
               'simple-example-to-illustrate-ordinary-least-squares-ridge-and-lasso-regression'),
              ('Ridge Regression', 2, None, 'ridge-regression'),
              ('Lasso Regression', 2, None, 'lasso-regression'),
              ('Yet another Example', 2, None, 'yet-another-example'),
              ('The OLS case', 2, None, 'the-ols-case'),
              ('The Ridge case', 2, None, 'the-ridge-case'),
              ('Writing the Cost Function',
               2,
               None,
               'writing-the-cost-function'),
              ('Lasso case', 2, None, 'lasso-case'),
              ('The first Case', 2, None, 'the-first-case'),
              ('Simple code for solving the above problem',
               2,
               None,
               'simple-code-for-solving-the-above-problem'),
              ('With Lasso Regression', 2, None, 'with-lasso-regression'),
              ('Another Example, now with a polynomial fit',
               2,
               None,
               'another-example-now-with-a-polynomial-fit'),
              ('To think about, first part',
               2,
               None,
               'to-think-about-first-part'),
              ('More thinking', 2, None, 'more-thinking'),
              ('Still thinking', 2, None, 'still-thinking'),
              ('What does centering (subtracting the mean values) mean '
               'mathematically?',
               2,
               None,
               'what-does-centering-subtracting-the-mean-values-mean-mathematically'),
              ('Further Manipulations', 2, None, 'further-manipulations'),
              ('Wrapping it up', 2, None, 'wrapping-it-up'),
              ('Linear Regression code, Intercept handling first',
               2,
               None,
               'linear-regression-code-intercept-handling-first'),
              ('Code Examples', 2, None, 'code-examples'),
              ('Taking out the mean', 2, None, 'taking-out-the-mean'),
              ('Friday September 9', 2, None, 'friday-september-9'),
              ('Linking the regression analysis with a statistical '
               'interpretation',
               2,
               None,
               'linking-the-regression-analysis-with-a-statistical-interpretation'),
              ('Assumptions made', 2, None, 'assumptions-made'),
              ('Expectation value and variance',
               2,
               None,
               'expectation-value-and-variance'),
              ('Expectation value and variance for $\\boldsymbol{\\beta}$',
               2,
               None,
               'expectation-value-and-variance-for-boldsymbol-beta'),
              ('Deriving OLS from a probability distribution',
               2,
               None,
               'deriving-ols-from-a-probability-distribution'),
              ('Independent and Identically Distrubuted (iid)',
               2,
               None,
               'independent-and-identically-distrubuted-iid'),
              ('Maximum Likelihood Estimation (MLE)',
               2,
               None,
               'maximum-likelihood-estimation-mle'),
              ('A new Cost Function', 2, None, 'a-new-cost-function'),
              ("More basic Statistics and Bayes' theorem",
               2,
               None,
               'more-basic-statistics-and-bayes-theorem'),
              ('Marginal Probability', 2, None, 'marginal-probability'),
              ('Conditional  Probability', 2, None, 'conditional-probability'),
              ("Bayes' Theorem", 2, None, 'bayes-theorem'),
              ("Interpretations of Bayes' Theorem",
               2,
               None,
               'interpretations-of-bayes-theorem'),
              ("Example of Usage of Bayes' theorem",
               2,
               None,
               'example-of-usage-of-bayes-theorem'),
              ('Doing it correctly', 2, None, 'doing-it-correctly'),
              ("Bayes' Theorem and Ridge and Lasso Regression",
               2,
               None,
               'bayes-theorem-and-ridge-and-lasso-regression'),
              ('Test Function for what happens with OLS, Ridge and Lasso',
               2,
               None,
               'test-function-for-what-happens-with-ols-ridge-and-lasso'),
              ("Invoking Bayes' theorem", 2, None, 'invoking-bayes-theorem'),
              ('Ridge and Bayes', 2, None, 'ridge-and-bayes'),
              ('Lasso and Bayes', 2, None, 'lasso-and-bayes')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript" async
 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="nuclear-bs.html">Practical Uncertainty Quantification and Emulator Development in Nuclear Physics</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs001.html#what-is-this-lecture-about" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;What is this lecture about?</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs002.html#many-folks-to-thank" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Many folks to thank</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs003.html#a-simple-perspective-on-the-interface-between-ml-and-physics" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;A simple perspective on the interface between ML and Physics</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs004.html#what-is-machine-learning" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;What is Machine Learning?</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs005.html#popular-libraries" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Popular libraries</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs006.html#types-of-machine-learning" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Types of Machine Learning</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs007.html#essential-elements-of-ml" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Essential elements of ML</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs008.html#an-optimization-minimization-problem" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;An optimization/minimization problem</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs009.html#a-frequentist-approach-to-data-analysis" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;A Frequentist approach to data analysis</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs010.html#what-is-a-good-model" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;What is a good model?</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs011.html#what-is-a-good-model-can-we-define-it" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;What is a good model? Can we define it?</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs012.html#ml-in-nuclear-physics" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;ML in Nuclear  Physics</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs013.html#ai-ml-and-some-statements-you-may-have-heard-and-what-do-they-mean" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;AI/ML and some statements you may have heard (and what do they mean?)</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs013.html#scientific-machine-learning" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Scientific Machine Learning</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs014.html#machine-learning-and-physics" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Machine Learning and Physics</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs015.html#lots-of-room-for-creativity" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Lots of room for creativity</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs016.html#machine-learning-and-nuclear-theory-why" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Machine learning and nuclear theory: Why?</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs017.html#the-plethora-of-machine-learning-algorithms-methods" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The plethora  of machine learning algorithms/methods</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs018.html#examples-of-machine-learning-methods-and-applications-in-nuclear-physics" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Examples of Machine Learning methods and applications in nuclear physics</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs019.html#examples-of-machine-learning-methods-and-applications-in-nuclear-physics-continues" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Examples of Machine Learning methods and applications in nuclear physics, continues</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs020.html#more-examples" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;More examples</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs021.html#and-more" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;And more</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs022.html#selected-references" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Selected references</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs023.html#unsupervised-learning-in-nuclear-physics-argon-46-by-solli-bazin-kuchera-mhj-strauss-https-www-sciencedirect-com-science-article-abs-pii-s0168900221004460-via-3dihub" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;"Unsupervised learning in nuclear physics, Argon-46 by Solli, Bazin, Kuchera, MHJ, Strauss.":"https://www.sciencedirect.com/science/article/abs/pii/S0168900221004460?via%3Dihub"</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs024.html#quantum-monte-carlo-and-deep-learning" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Quantum Monte Carlo and deep learning</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs025.html#monte-carlo-methods-and-neural-networks" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Monte Carlo methods and Neural Networks</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs026.html#deep-learning-neural-networks-variational-monte-carlo-calculations-of-a-le-4-nuclei-with-an-artificial-neural-network-correlator-ansatz-by-adams-et-al-https-journals-aps-org-prl-abstract-10-1103-physrevlett-127-022502" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Deep learning neural networks, "Variational Monte Carlo calculations of \( A\le 4 \) nuclei with an artificial neural-network correlator ansatz by Adams et al.":"https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.127.022502"</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs027.html#gnech-et-al-variational-monte-carlo-calculations-of-a-le-6-nuclei-few-body-systems-63-2022-https-link-springer-com-article-10-1007-s00601-021-01706-0" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;"Gnech et al, Variational Monte Carlo calculations of \( A\le 6 \) nuclei Few Body Systems 63, (2022)":"https://link.springer.com/article/10.1007/s00601-021-01706-0"</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs028.html#the-electron-gas-in-three-dimensions-with-n-14-electrons-wigner-seitz-radius-r-s-2-ry" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The electron gas in three dimensions with \( N=14 \) electrons (Wigner-Seitz radius \( r_s=2 \) Ry)</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs029.html#neutron-matter-with-n-14-neutron" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Neutron matter with \( N=14 \) neutron</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs030.html#electrons-in-a-harmonic-oscillator-trap-in-two-dimensions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Electrons in a harmonic oscillator trap in two dimensions</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs031.html#quantum-dots-and-boltzmann-machines-onebody-densities-n-6-hbar-omega-0-1-a-u" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Quantum dots and Boltzmann machines, onebody densities \( N=6 \), \( \hbar\omega=0.1 \) a.u.</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs032.html#onebody-densities-n-30-hbar-omega-1-0-a-u" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Onebody densities \( N=30 \), \( \hbar\omega=1.0 \) a.u.</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs033.html#onebody-densities-n-30-hbar-omega-0-1-a-u" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Onebody densities \( N=30 \), \( \hbar\omega=0.1 \) a.u.</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs034.html#extrapolations-and-model-interpretability" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Extrapolations and model interpretability</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs035.html#physics-based-statistical-learning-and-data-analysis" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Physics based statistical learning and data analysis</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs179.html#bayes-theorem" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Bayes' Theorem</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs037.html#quantified-limits-of-the-nuclear-landscape" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Quantified limits of the nuclear landscape</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs038.html#constraining-the-equation-of-state-for-dense-nuclear-matter" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Constraining the equation of state for dense nuclear matter</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs039.html#observations-or-conclusions-if-you-prefer" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Observations (or conclusions if you prefer)</a></li>
     <!-- navigation toc: --> <li><a href="#possible-start-to-raise-awareness-about-ml-in-our-field" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Possible start to raise awareness about ML in our field</a></li>
     <!-- navigation toc: --> <li><a href="#to-our-real-data-nuclear-binding-energies-brief-reminder-on-masses-and-binding-energies" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;To our real data: nuclear binding energies. Brief reminder on masses and binding energies</a></li>
     <!-- navigation toc: --> <li><a href="#organizing-our-data" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Organizing our data</a></li>
     <!-- navigation toc: --> <li><a href="#seeing-the-wood-for-the-trees" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Seeing the wood for the trees</a></li>
     <!-- navigation toc: --> <li><a href="#and-what-about-using-neural-networks" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;And what about using neural networks?</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs041.html#background-material" style="font-size: 80%;"><b>Background material</b></a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs042.html#why-linear-regression-aka-ordinary-least-squares-and-family" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Why Linear Regression (aka Ordinary Least Squares and family)</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs067.html#regression-analysis-overarching-aims" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Regression analysis, overarching aims</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs068.html#regression-analysis-overarching-aims-ii" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Regression analysis, overarching aims II</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs086.html#examples" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Examples</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs070.html#general-linear-models" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;General linear models</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs071.html#rewriting-the-fitting-procedure-as-a-linear-algebra-problem" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Rewriting the fitting procedure as a linear algebra problem</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs072.html#rewriting-the-fitting-procedure-as-a-linear-algebra-problem-more-details" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Rewriting the fitting procedure as a linear algebra problem, more details</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs074.html#generalizing-the-fitting-procedure-as-a-linear-algebra-problem" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Generalizing the fitting procedure as a linear algebra problem</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs074.html#generalizing-the-fitting-procedure-as-a-linear-algebra-problem" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Generalizing the fitting procedure as a linear algebra problem</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs075.html#optimizing-our-parameters" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Optimizing our parameters</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs076.html#our-model-for-the-nuclear-binding-energies" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Our model for the nuclear binding energies</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs077.html#optimizing-our-parameters-more-details" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Optimizing our parameters, more details</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs082.html#interpretations-and-optimizing-our-parameters" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Interpretations and optimizing our parameters</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs082.html#interpretations-and-optimizing-our-parameters" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Interpretations and optimizing our parameters</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs080.html#some-useful-matrix-and-vector-expressions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Some useful matrix and vector expressions</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs082.html#interpretations-and-optimizing-our-parameters" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Interpretations and optimizing our parameters</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs083.html#own-code-for-ordinary-least-squares" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Own code for Ordinary Least Squares</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs084.html#adding-error-analysis-and-training-set-up" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Adding error analysis and training set up</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs065.html#the-chi-2-function" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The \( \chi^2 \) function</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs065.html#the-chi-2-function" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The \( \chi^2 \) function</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs065.html#the-chi-2-function" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The \( \chi^2 \) function</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs065.html#the-chi-2-function" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The \( \chi^2 \) function</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs065.html#the-chi-2-function" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The \( \chi^2 \) function</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs065.html#the-chi-2-function" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The \( \chi^2 \) function</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs066.html#why-linear-regression-aka-ordinary-least-squares-and-family-repeat-from-last-week" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Why Linear Regression (aka Ordinary Least Squares and family), repeat from last week</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs067.html#regression-analysis-overarching-aims" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Regression analysis, overarching aims</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs068.html#regression-analysis-overarching-aims-ii" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Regression analysis, overarching aims II</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs086.html#examples" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Examples</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs070.html#general-linear-models" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;General linear models</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs071.html#rewriting-the-fitting-procedure-as-a-linear-algebra-problem" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Rewriting the fitting procedure as a linear algebra problem</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs072.html#rewriting-the-fitting-procedure-as-a-linear-algebra-problem-more-details" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Rewriting the fitting procedure as a linear algebra problem, more details</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs074.html#generalizing-the-fitting-procedure-as-a-linear-algebra-problem" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Generalizing the fitting procedure as a linear algebra problem</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs074.html#generalizing-the-fitting-procedure-as-a-linear-algebra-problem" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Generalizing the fitting procedure as a linear algebra problem</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs075.html#optimizing-our-parameters" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Optimizing our parameters</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs076.html#our-model-for-the-nuclear-binding-energies" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Our model for the nuclear binding energies</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs077.html#optimizing-our-parameters-more-details" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Optimizing our parameters, more details</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs082.html#interpretations-and-optimizing-our-parameters" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Interpretations and optimizing our parameters</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs082.html#interpretations-and-optimizing-our-parameters" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Interpretations and optimizing our parameters</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs080.html#some-useful-matrix-and-vector-expressions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Some useful matrix and vector expressions</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs081.html#meet-the-hessian-matrix" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Meet the Hessian Matrix</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs082.html#interpretations-and-optimizing-our-parameters" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Interpretations and optimizing our parameters</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs083.html#own-code-for-ordinary-least-squares" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Own code for Ordinary Least Squares</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs084.html#adding-error-analysis-and-training-set-up" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Adding error analysis and training set up</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs085.html#splitting-our-data-in-training-and-test-data" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Splitting our Data in Training and Test data</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs086.html#examples" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Examples</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs087.html#making-your-own-test-train-splitting" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Making your own test-train splitting</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs088.html#the-boston-housing-data-example" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The Boston housing data example</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs089.html#housing-data-the-code" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Housing data, the code</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs090.html#reducing-the-number-of-degrees-of-freedom-overarching-view" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Reducing the number of degrees of freedom, overarching view</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs091.html#preprocessing-our-data" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Preprocessing our data</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs092.html#functionality-in-scikit-learn" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Functionality in Scikit-Learn</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs093.html#more-preprocessing" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;More preprocessing</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs094.html#frequently-used-scaling-functions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Frequently used scaling functions</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs095.html#example-of-own-standard-scaling" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Example of own Standard scaling</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs096.html#min-max-scaling" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Min-Max Scaling</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs097.html#testing-the-means-squared-error-as-function-of-complexity" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Testing the Means Squared Error as function of Complexity</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs098.html#more-preprocessing-examples-franke-function-and-regression" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;More preprocessing examples, Franke function and regression</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs099.html#mathematical-interpretation-of-ordinary-least-squares" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Mathematical Interpretation of Ordinary Least Squares</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs100.html#residual-error" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Residual Error</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs101.html#simple-case" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Simple case</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs102.html#the-singular-value-decomposition" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The singular value decomposition</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs103.html#linear-regression-problems" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Linear Regression Problems</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs104.html#fixing-the-singularity" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Fixing the singularity</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs105.html#basic-math-of-the-svd" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Basic math of the SVD</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs106.html#the-svd-a-fantastic-algorithm" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The SVD, a Fantastic Algorithm</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs107.html#economy-size-svd" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Economy-size SVD</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs108.html#codes-for-the-svd" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Codes for the SVD</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs109.html#note-about-svd-calculations" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Note about SVD Calculations</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs110.html#mathematics-of-the-svd-and-implications" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Mathematics of the SVD and implications</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs111.html#example-matrix" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Example Matrix</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs112.html#setting-up-the-matrix-to-be-inverted" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Setting up the Matrix to be inverted</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs113.html#further-properties-important-for-our-analyses-later" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Further properties (important for our analyses later)</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs114.html#meet-the-covariance-matrix" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Meet the Covariance Matrix</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs115.html#introducing-the-covariance-and-correlation-functions" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Introducing the Covariance and Correlation functions</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs116.html#covariance-and-correlation-matrix" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Covariance and Correlation Matrix</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs117.html#correlation-function-and-design-feature-matrix" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Correlation Function and Design/Feature Matrix</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs118.html#covariance-matrix-examples" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Covariance Matrix Examples</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs119.html#correlation-matrix" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Correlation Matrix</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs120.html#correlation-matrix-with-pandas" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Correlation Matrix with Pandas</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs121.html#correlation-matrix-with-pandas-and-the-franke-function" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Correlation Matrix with Pandas and the Franke function</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs122.html#rewriting-the-covariance-and-or-correlation-matrix" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Rewriting the Covariance and/or Correlation Matrix</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs123.html#linking-with-the-svd" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Linking with the SVD</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs133.html#what-does-it-mean" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;What does it mean?</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs134.html#and-finally-boldsymbol-x-boldsymbol-x-t" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;And finally  \( \boldsymbol{X}\boldsymbol{X}^T \)</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs137.html#ridge-and-lasso-regression" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Ridge and LASSO Regression</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs139.html#deriving-the-ridge-regression-equations" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Deriving the  Ridge Regression Equations</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs143.html#interpreting-the-ridge-results" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Interpreting the Ridge results</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs144.html#more-interpretations" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;More interpretations</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs145.html#deriving-the-lasso-regression-equations" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Deriving the  Lasso Regression Equations</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs131.html#exercises-for-week-35" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Exercises for week 35</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs131.html#exercise-1-setting-up-various-python-environments" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Exercise 1: Setting up various Python environments</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs132.html#linear-regression-and-the-svd" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Linear Regression and  the SVD</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs133.html#what-does-it-mean" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;What does it mean?</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs134.html#and-finally-boldsymbol-x-boldsymbol-x-t" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;And finally  \( \boldsymbol{X}\boldsymbol{X}^T \)</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs135.html#code-for-svd-and-inversion-of-matrices" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Code for SVD and Inversion of Matrices</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs136.html#inverse-of-rectangular-matrix" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Inverse of Rectangular Matrix</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs137.html#ridge-and-lasso-regression" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Ridge and LASSO Regression</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs138.html#from-ols-to-ridge-and-lasso" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;From OLS to Ridge and Lasso</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs139.html#deriving-the-ridge-regression-equations" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Deriving the  Ridge Regression Equations</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs140.html#note-on-scikit-learn" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Note on Scikit-Learn</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs141.html#comparison-with-ols" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Comparison with OLS</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs142.html#svd-analysis" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;SVD analysis</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs143.html#interpreting-the-ridge-results" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Interpreting the Ridge results</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs144.html#more-interpretations" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;More interpretations</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs145.html#deriving-the-lasso-regression-equations" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Deriving the  Lasso Regression Equations</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs146.html#simple-example-to-illustrate-ordinary-least-squares-ridge-and-lasso-regression" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Simple example to illustrate Ordinary Least Squares, Ridge and Lasso Regression</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs147.html#ridge-regression" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Ridge Regression</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs148.html#lasso-regression" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Lasso Regression</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs149.html#yet-another-example" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Yet another Example</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs150.html#the-ols-case" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The OLS case</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs151.html#the-ridge-case" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The Ridge case</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs152.html#writing-the-cost-function" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Writing the Cost Function</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs153.html#lasso-case" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Lasso case</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs154.html#the-first-case" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;The first Case</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs155.html#simple-code-for-solving-the-above-problem" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Simple code for solving the above problem</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs156.html#with-lasso-regression" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;With Lasso Regression</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs157.html#another-example-now-with-a-polynomial-fit" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Another Example, now with a polynomial fit</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs158.html#to-think-about-first-part" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;To think about, first part</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs159.html#more-thinking" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;More thinking</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs160.html#still-thinking" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Still thinking</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs161.html#what-does-centering-subtracting-the-mean-values-mean-mathematically" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;What does centering (subtracting the mean values) mean mathematically?</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs162.html#further-manipulations" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Further Manipulations</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs163.html#wrapping-it-up" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Wrapping it up</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs164.html#linear-regression-code-intercept-handling-first" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Linear Regression code, Intercept handling first</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs165.html#code-examples" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Code Examples</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs166.html#taking-out-the-mean" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Taking out the mean</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs167.html#friday-september-9" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Friday September 9</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs168.html#linking-the-regression-analysis-with-a-statistical-interpretation" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Linking the regression analysis with a statistical interpretation</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs169.html#assumptions-made" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Assumptions made</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs170.html#expectation-value-and-variance" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Expectation value and variance</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs171.html#expectation-value-and-variance-for-boldsymbol-beta" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Expectation value and variance for \( \boldsymbol{\beta} \)</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs172.html#deriving-ols-from-a-probability-distribution" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Deriving OLS from a probability distribution</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs173.html#independent-and-identically-distrubuted-iid" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Independent and Identically Distrubuted (iid)</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs174.html#maximum-likelihood-estimation-mle" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Maximum Likelihood Estimation (MLE)</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs175.html#a-new-cost-function" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;A new Cost Function</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs176.html#more-basic-statistics-and-bayes-theorem" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;More basic Statistics and Bayes' theorem</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs177.html#marginal-probability" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Marginal Probability</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs178.html#conditional-probability" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Conditional  Probability</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs179.html#bayes-theorem" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Bayes' Theorem</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs180.html#interpretations-of-bayes-theorem" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Interpretations of Bayes' Theorem</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs181.html#example-of-usage-of-bayes-theorem" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Example of Usage of Bayes' theorem</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs182.html#doing-it-correctly" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Doing it correctly</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs183.html#bayes-theorem-and-ridge-and-lasso-regression" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Bayes' Theorem and Ridge and Lasso Regression</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs184.html#test-function-for-what-happens-with-ols-ridge-and-lasso" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Test Function for what happens with OLS, Ridge and Lasso</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs185.html#invoking-bayes-theorem" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Invoking Bayes' theorem</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs186.html#ridge-and-bayes" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Ridge and Bayes</a></li>
     <!-- navigation toc: --> <li><a href="._mlnuclear-bs187.html#lasso-and-bayes" style="font-size: 80%;">&nbsp;&nbsp;&nbsp;Lasso and Bayes</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->
<div class="container">
<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->
<a name="part0040"></a>
<!-- !split -->
<h2 id="possible-start-to-raise-awareness-about-ml-in-our-field" class="anchor">Possible start to raise awareness about ML in our field </h2>
<div class="panel panel-default">
<div class="panel-body">
<!-- subsequent paragraphs come in larger fonts, so start with a paragraph -->
<ul>
<li> Make an ML challenge in nuclear physics a la <a href="https://home.cern/news/news/computing/higgs-boson-machine-learning-challenge" target="_self">Learning to discover: the Higgs boson machine learning challenge</a>. Alternatively go to kaggle.com at <a href="https://www.kaggle.com/c/higgs-boson" target="_self"><tt>https://www.kaggle.com/c/higgs-boson</tt></a></li>
<li> HEP@CERN and HEP in general have made significant impacts in the field of machine learning and AI. Something to learn from</li>
</ul>
</div>
</div>

<h3 id="to-our-real-data-nuclear-binding-energies-brief-reminder-on-masses-and-binding-energies" class="anchor">To our real data: nuclear binding energies. Brief reminder on masses and binding energies </h3>

<p>Let us now dive into  nuclear physics and remind ourselves briefly about some basic features about binding
energies.  A basic quantity which can be measured for the ground
states of nuclei is the atomic mass \( M(N, Z) \) of the neutral atom with
atomic mass number \( A \) and charge \( Z \). The number of neutrons is \( N \). There are indeed several sophisticated experiments worldwide which allow us to measure this quantity to high precision (parts per million even). 
</p>

<p>Atomic masses are usually tabulated in terms of the mass excess defined by</p>
$$
\Delta M(N, Z) =  M(N, Z) - uA,
$$

<p>where \( u \) is the Atomic Mass Unit </p>
$$
u = M(^{12}\mathrm{C})/12 = 931.4940954(57) \hspace{0.1cm} \mathrm{MeV}/c^2.
$$

<p>The nucleon masses are</p>
$$
m_p =  1.00727646693(9)u,
$$

<p>and</p>
$$
m_n = 939.56536(8)\hspace{0.1cm} \mathrm{MeV}/c^2 = 1.0086649156(6)u.
$$

<p>In the <a href="http://nuclearmasses.org/resources_folder/Wang_2017_Chinese_Phys_C_41_030003.pdf" target="_self">2016 mass evaluation of by W.J.Huang, G.Audi, M.Wang, F.G.Kondev, S.Naimi and X.Xu</a>
there are data on masses and decays of 3437 nuclei.
</p>

<p>The nuclear binding energy is defined as the energy required to break
up a given nucleus into its constituent parts of \( N \) neutrons and \( Z \)
protons. In terms of the atomic masses \( M(N, Z) \) the binding energy is
defined by
</p>

$$
BE(N, Z) = ZM_H c^2 + Nm_n c^2 - M(N, Z)c^2 ,
$$

<p>where \( M_H \) is the mass of the hydrogen atom and \( m_n \) is the mass of the neutron.
In terms of the mass excess the binding energy is given by
</p>
$$
BE(N, Z) = Z\Delta_H c^2 + N\Delta_n c^2 -\Delta(N, Z)c^2 ,
$$

<p>where \( \Delta_H c^2 = 7.2890 \) MeV and \( \Delta_n c^2 = 8.0713 \) MeV.</p>

<p>A popular and physically intuitive model which can be used to parametrize 
the experimental binding energies as function of \( A \), is the so-called 
<b>liquid drop model</b>. The ansatz is based on the following expression
</p>

$$ 
BE(N,Z) = a_1A-a_2A^{2/3}-a_3\frac{Z^2}{A^{1/3}}-a_4\frac{(N-Z)^2}{A},
$$

<p>where \( A \) stands for the number of nucleons and the $a_i$s are parameters which are determined by a fit 
to the experimental data.  
</p>

<p>To arrive at the above expression we have assumed that we can make the following assumptions:</p>

<ul>
 <li> There is a volume term \( a_1A \) proportional with the number of nucleons (the energy is also an extensive quantity). When an assembly of nucleons of the same size is packed together into the smallest volume, each interior nucleon has a certain number of other nucleons in contact with it. This contribution is proportional to the volume.</li>
 <li> There is a surface energy term \( a_2A^{2/3} \). The assumption here is that a nucleon at the surface of a nucleus interacts with fewer other nucleons than one in the interior of the nucleus and hence its binding energy is less. This surface energy term takes that into account and is therefore negative and is proportional to the surface area.</li>
 <li> There is a Coulomb energy term \( a_3\frac{Z^2}{A^{1/3}} \). The electric repulsion between each pair of protons in a nucleus yields less binding.</li> 
 <li> There is an asymmetry term \( a_4\frac{(N-Z)^2}{A} \). This term is associated with the Pauli exclusion principle and reflects the fact that the proton-neutron interaction is more attractive on the average than the neutron-neutron and proton-proton interactions.</li>
</ul>
<p>We could also add a so-called pairing term, which is a correction term that
arises from the tendency of proton pairs and neutron pairs to
occur. An even number of particles is more stable than an odd number. 
</p>
<h3 id="organizing-our-data" class="anchor">Organizing our data </h3>

<p>Let us start with reading and organizing our data. 
We start with the compilation of masses and binding energies from 2016.
After having downloaded this file to our own computer, we are now ready to read the file and start structuring our data.
</p>

<p>We start with preparing folders for storing our calculations and the data file over masses and binding energies. We import also various modules that we will find useful in order to present various Machine Learning methods. Here we focus mainly on the functionality of <b>scikit-learn</b>.</p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #408080; font-style: italic"># Common imports</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">numpy</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">np</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">pandas</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">pd</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">matplotlib.pyplot</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">plt</span>
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">sklearn.linear_model</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">skl</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.model_selection</span> <span style="color: #008000; font-weight: bold">import</span> train_test_split
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.metrics</span> <span style="color: #008000; font-weight: bold">import</span> mean_squared_error, r2_score, mean_absolute_error
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">os</span>

<span style="color: #408080; font-style: italic"># Where to save the figures and data files</span>
PROJECT_ROOT_DIR <span style="color: #666666">=</span> <span style="color: #BA2121">&quot;Results&quot;</span>
FIGURE_ID <span style="color: #666666">=</span> <span style="color: #BA2121">&quot;Results/FigureFiles&quot;</span>
DATA_ID <span style="color: #666666">=</span> <span style="color: #BA2121">&quot;DataFiles/&quot;</span>

<span style="color: #008000; font-weight: bold">if</span> <span style="color: #AA22FF; font-weight: bold">not</span> os<span style="color: #666666">.</span>path<span style="color: #666666">.</span>exists(PROJECT_ROOT_DIR):
    os<span style="color: #666666">.</span>mkdir(PROJECT_ROOT_DIR)

<span style="color: #008000; font-weight: bold">if</span> <span style="color: #AA22FF; font-weight: bold">not</span> os<span style="color: #666666">.</span>path<span style="color: #666666">.</span>exists(FIGURE_ID):
    os<span style="color: #666666">.</span>makedirs(FIGURE_ID)

<span style="color: #008000; font-weight: bold">if</span> <span style="color: #AA22FF; font-weight: bold">not</span> os<span style="color: #666666">.</span>path<span style="color: #666666">.</span>exists(DATA_ID):
    os<span style="color: #666666">.</span>makedirs(DATA_ID)

<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">image_path</span>(fig_id):
    <span style="color: #008000; font-weight: bold">return</span> os<span style="color: #666666">.</span>path<span style="color: #666666">.</span>join(FIGURE_ID, fig_id)

<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">data_path</span>(dat_id):
    <span style="color: #008000; font-weight: bold">return</span> os<span style="color: #666666">.</span>path<span style="color: #666666">.</span>join(DATA_ID, dat_id)

<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">save_fig</span>(fig_id):
    plt<span style="color: #666666">.</span>savefig(image_path(fig_id) <span style="color: #666666">+</span> <span style="color: #BA2121">&quot;.png&quot;</span>, <span style="color: #008000">format</span><span style="color: #666666">=</span><span style="color: #BA2121">&#39;png&#39;</span>)

infile <span style="color: #666666">=</span> <span style="color: #008000">open</span>(data_path(<span style="color: #BA2121">&quot;MassEval2016.dat&quot;</span>),<span style="color: #BA2121">&#39;r&#39;</span>)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>

<p>Before we proceed, we define also a function for making our plots. You can obviously avoid this and simply set up various <b>matplotlib</b> commands every time you need them. You may however find it convenient to collect all such commands in one function and simply call this function. </p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">pylab</span> <span style="color: #008000; font-weight: bold">import</span> plt, mpl
plt<span style="color: #666666">.</span>style<span style="color: #666666">.</span>use(<span style="color: #BA2121">&#39;seaborn&#39;</span>)
mpl<span style="color: #666666">.</span>rcParams[<span style="color: #BA2121">&#39;font.family&#39;</span>] <span style="color: #666666">=</span> <span style="color: #BA2121">&#39;serif&#39;</span>

<span style="color: #008000; font-weight: bold">def</span> <span style="color: #0000FF">MakePlot</span>(x,y, styles, labels, axlabels):
    plt<span style="color: #666666">.</span>figure(figsize<span style="color: #666666">=</span>(<span style="color: #666666">10</span>,<span style="color: #666666">6</span>))
    <span style="color: #008000; font-weight: bold">for</span> i <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">range</span>(<span style="color: #008000">len</span>(x)):
        plt<span style="color: #666666">.</span>plot(x[i], y[i], styles[i], label <span style="color: #666666">=</span> labels[i])
        plt<span style="color: #666666">.</span>xlabel(axlabels[<span style="color: #666666">0</span>])
        plt<span style="color: #666666">.</span>ylabel(axlabels[<span style="color: #666666">1</span>])
    plt<span style="color: #666666">.</span>legend(loc<span style="color: #666666">=0</span>)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>

<p>Our next step is to read the data on experimental binding energies and
reorganize them as functions of the mass number \( A \), the number of
protons \( Z \) and neutrons \( N \) using <b>pandas</b>.  Before we do this it is
always useful (unless you have a binary file or other types of compressed
data) to actually open the file and simply take a look at it!
</p>

<p>In particular, the program that outputs the final nuclear masses is written in Fortran with a specific format. It means that we need to figure out the format and which columns contain the data we are interested in. Pandas comes with a function that reads formatted output. After having admired the file, we are now ready to start massaging it with <b>pandas</b>. The file begins with some basic format information.</p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #BA2121; font-style: italic">&quot;&quot;&quot;                                                                                                                         </span>
<span style="color: #BA2121; font-style: italic">This is taken from the data file of the mass 2016 evaluation.                                                               </span>
<span style="color: #BA2121; font-style: italic">All files are 3436 lines long with 124 character per line.                                                                  </span>
<span style="color: #BA2121; font-style: italic">       Headers are 39 lines long.                                                                                           </span>
<span style="color: #BA2121; font-style: italic">   col 1     :  Fortran character control: 1 = page feed  0 = line feed                                                     </span>
<span style="color: #BA2121; font-style: italic">   format    :  a1,i3,i5,i5,i5,1x,a3,a4,1x,f13.5,f11.5,f11.3,f9.3,1x,a2,f11.3,f9.3,1x,i3,1x,f12.5,f11.5                     </span>
<span style="color: #BA2121; font-style: italic">   These formats are reflected in the pandas widths variable below, see the statement                                       </span>
<span style="color: #BA2121; font-style: italic">   widths=(1,3,5,5,5,1,3,4,1,13,11,11,9,1,2,11,9,1,3,1,12,11,1),                                                            </span>
<span style="color: #BA2121; font-style: italic">   Pandas has also a variable header, with length 39 in this case.                                                          </span>
<span style="color: #BA2121; font-style: italic">&quot;&quot;&quot;</span>
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>

<p>The data we are interested in are in columns 2, 3, 4 and 11, giving us
the number of neutrons, protons, mass numbers and binding energies,
respectively. We add also for the sake of completeness the element name. The data are in fixed-width formatted lines and we will
covert them into the <b>pandas</b> DataFrame structure.
</p>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #408080; font-style: italic"># Read the experimental data with Pandas</span>
Masses <span style="color: #666666">=</span> pd<span style="color: #666666">.</span>read_fwf(infile, usecols<span style="color: #666666">=</span>(<span style="color: #666666">2</span>,<span style="color: #666666">3</span>,<span style="color: #666666">4</span>,<span style="color: #666666">6</span>,<span style="color: #666666">11</span>),
              names<span style="color: #666666">=</span>(<span style="color: #BA2121">&#39;N&#39;</span>, <span style="color: #BA2121">&#39;Z&#39;</span>, <span style="color: #BA2121">&#39;A&#39;</span>, <span style="color: #BA2121">&#39;Element&#39;</span>, <span style="color: #BA2121">&#39;Ebinding&#39;</span>),
              widths<span style="color: #666666">=</span>(<span style="color: #666666">1</span>,<span style="color: #666666">3</span>,<span style="color: #666666">5</span>,<span style="color: #666666">5</span>,<span style="color: #666666">5</span>,<span style="color: #666666">1</span>,<span style="color: #666666">3</span>,<span style="color: #666666">4</span>,<span style="color: #666666">1</span>,<span style="color: #666666">13</span>,<span style="color: #666666">11</span>,<span style="color: #666666">11</span>,<span style="color: #666666">9</span>,<span style="color: #666666">1</span>,<span style="color: #666666">2</span>,<span style="color: #666666">11</span>,<span style="color: #666666">9</span>,<span style="color: #666666">1</span>,<span style="color: #666666">3</span>,<span style="color: #666666">1</span>,<span style="color: #666666">12</span>,<span style="color: #666666">11</span>,<span style="color: #666666">1</span>),
              header<span style="color: #666666">=39</span>,
              index_col<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">False</span>)

<span style="color: #408080; font-style: italic"># Extrapolated values are indicated by &#39;#&#39; in place of the decimal place, so</span>
<span style="color: #408080; font-style: italic"># the Ebinding column won&#39;t be numeric. Coerce to float and drop these entries.</span>
Masses[<span style="color: #BA2121">&#39;Ebinding&#39;</span>] <span style="color: #666666">=</span> pd<span style="color: #666666">.</span>to_numeric(Masses[<span style="color: #BA2121">&#39;Ebinding&#39;</span>], errors<span style="color: #666666">=</span><span style="color: #BA2121">&#39;coerce&#39;</span>)
Masses <span style="color: #666666">=</span> Masses<span style="color: #666666">.</span>dropna()
<span style="color: #408080; font-style: italic"># Convert from keV to MeV.</span>
Masses[<span style="color: #BA2121">&#39;Ebinding&#39;</span>] <span style="color: #666666">/=</span> <span style="color: #666666">1000</span>

<span style="color: #408080; font-style: italic"># Group the DataFrame by nucleon number, A.</span>
Masses <span style="color: #666666">=</span> Masses<span style="color: #666666">.</span>groupby(<span style="color: #BA2121">&#39;A&#39;</span>)
<span style="color: #408080; font-style: italic"># Find the rows of the grouped DataFrame with the maximum binding energy.</span>
Masses <span style="color: #666666">=</span> Masses<span style="color: #666666">.</span>apply(<span style="color: #008000; font-weight: bold">lambda</span> t: t[t<span style="color: #666666">.</span>Ebinding<span style="color: #666666">==</span>t<span style="color: #666666">.</span>Ebinding<span style="color: #666666">.</span>max()])
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>

<p>We have now read in the data, grouped them according to the variables we are interested in. 
We see how easy it is to reorganize the data using <b>pandas</b>. If we
were to do these operations in C/C++ or Fortran, we would have had to
write various functions/subroutines which perform the above
reorganizations for us.  Having reorganized the data, we can now start
to make some simple fits using both the functionalities in <b>numpy</b> and
<b>Scikit-Learn</b> afterwards. 
</p>

<p>Now we define five variables which contain
the number of nucleons \( A \), the number of protons \( Z \) and the number of neutrons \( N \), the element name and finally the energies themselves.
</p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;">A <span style="color: #666666">=</span> Masses[<span style="color: #BA2121">&#39;A&#39;</span>]
Z <span style="color: #666666">=</span> Masses[<span style="color: #BA2121">&#39;Z&#39;</span>]
N <span style="color: #666666">=</span> Masses[<span style="color: #BA2121">&#39;N&#39;</span>]
Element <span style="color: #666666">=</span> Masses[<span style="color: #BA2121">&#39;Element&#39;</span>]
Energies <span style="color: #666666">=</span> Masses[<span style="color: #BA2121">&#39;Ebinding&#39;</span>]
<span style="color: #008000">print</span>(Masses)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>

<p>The next step, and we will define this mathematically later, is to set up the so-called <b>design matrix</b>. We will throughout call this matrix \( \boldsymbol{X} \).
It has dimensionality \( p\times n \), where \( n \) is the number of data points and \( p \) are the so-called predictors. In our case here they are given by the number of polynomials in \( A \) we wish to include in the fit. 
</p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #408080; font-style: italic"># Now we set up the design matrix X</span>
X <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((<span style="color: #008000">len</span>(A),<span style="color: #666666">5</span>))
X[:,<span style="color: #666666">0</span>] <span style="color: #666666">=</span> <span style="color: #666666">1</span>
X[:,<span style="color: #666666">1</span>] <span style="color: #666666">=</span> A
X[:,<span style="color: #666666">2</span>] <span style="color: #666666">=</span> A<span style="color: #666666">**</span>(<span style="color: #666666">2.0/3.0</span>)
X[:,<span style="color: #666666">3</span>] <span style="color: #666666">=</span> A<span style="color: #666666">**</span>(<span style="color: #666666">-1.0/3.0</span>)
X[:,<span style="color: #666666">4</span>] <span style="color: #666666">=</span> A<span style="color: #666666">**</span>(<span style="color: #666666">-1.0</span>)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>

<p>With <b>scikitlearn</b> we are now ready to use linear regression and fit our data.</p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;">clf <span style="color: #666666">=</span> skl<span style="color: #666666">.</span>LinearRegression()<span style="color: #666666">.</span>fit(X, Energies)
fity <span style="color: #666666">=</span> clf<span style="color: #666666">.</span>predict(X)
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>

<p>Pretty simple!  
Now we can print measures of how our fit is doing, the coefficients from the fits and plot the final fit together with our data.
</p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #408080; font-style: italic"># The mean squared error                               </span>
<span style="color: #008000">print</span>(<span style="color: #BA2121">&quot;Mean squared error: </span><span style="color: #BB6688; font-weight: bold">%.2f</span><span style="color: #BA2121">&quot;</span> <span style="color: #666666">%</span> mean_squared_error(Energies, fity))
<span style="color: #408080; font-style: italic"># Explained variance score: 1 is perfect prediction                                 </span>
<span style="color: #008000">print</span>(<span style="color: #BA2121">&#39;Variance score: </span><span style="color: #BB6688; font-weight: bold">%.2f</span><span style="color: #BA2121">&#39;</span> <span style="color: #666666">%</span> r2_score(Energies, fity))
<span style="color: #408080; font-style: italic"># Mean absolute error                                                           </span>
<span style="color: #008000">print</span>(<span style="color: #BA2121">&#39;Mean absolute error: </span><span style="color: #BB6688; font-weight: bold">%.2f</span><span style="color: #BA2121">&#39;</span> <span style="color: #666666">%</span> mean_absolute_error(Energies, fity))
<span style="color: #008000">print</span>(clf<span style="color: #666666">.</span>coef_, clf<span style="color: #666666">.</span>intercept_)

Masses[<span style="color: #BA2121">&#39;Eapprox&#39;</span>]  <span style="color: #666666">=</span> fity
<span style="color: #408080; font-style: italic"># Generate a plot comparing the experimental with the fitted values values.</span>
fig, ax <span style="color: #666666">=</span> plt<span style="color: #666666">.</span>subplots()
ax<span style="color: #666666">.</span>set_xlabel(<span style="color: #BA2121">r&#39;$A = N + Z$&#39;</span>)
ax<span style="color: #666666">.</span>set_ylabel(<span style="color: #BA2121">r&#39;$E_\mathrm</span><span style="color: #BB6688; font-weight: bold">{bind}</span><span style="color: #BA2121">\,/\mathrm</span><span style="color: #BB6688; font-weight: bold">{MeV}</span><span style="color: #BA2121">$&#39;</span>)
ax<span style="color: #666666">.</span>plot(Masses[<span style="color: #BA2121">&#39;A&#39;</span>], Masses[<span style="color: #BA2121">&#39;Ebinding&#39;</span>], alpha<span style="color: #666666">=0.7</span>, lw<span style="color: #666666">=2</span>,
            label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;Ame2016&#39;</span>)
ax<span style="color: #666666">.</span>plot(Masses[<span style="color: #BA2121">&#39;A&#39;</span>], Masses[<span style="color: #BA2121">&#39;Eapprox&#39;</span>], alpha<span style="color: #666666">=0.7</span>, lw<span style="color: #666666">=2</span>, c<span style="color: #666666">=</span><span style="color: #BA2121">&#39;m&#39;</span>,
            label<span style="color: #666666">=</span><span style="color: #BA2121">&#39;Fit&#39;</span>)
ax<span style="color: #666666">.</span>legend()
save_fig(<span style="color: #BA2121">&quot;Masses2016&quot;</span>)
plt<span style="color: #666666">.</span>show()
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>
<h3 id="seeing-the-wood-for-the-trees" class="anchor">Seeing the wood for the trees </h3>

<p>As a teaser, let us now see how we can do this with decision trees using <b>scikit-learn</b>. Later we will switch to so-called <b>random forests</b>!</p>


<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #408080; font-style: italic">#Decision Tree Regression</span>
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.tree</span> <span style="color: #008000; font-weight: bold">import</span> DecisionTreeRegressor
regr_1<span style="color: #666666">=</span>DecisionTreeRegressor(max_depth<span style="color: #666666">=5</span>)
regr_2<span style="color: #666666">=</span>DecisionTreeRegressor(max_depth<span style="color: #666666">=7</span>)
regr_3<span style="color: #666666">=</span>DecisionTreeRegressor(max_depth<span style="color: #666666">=9</span>)
regr_1<span style="color: #666666">.</span>fit(X, Energies)
regr_2<span style="color: #666666">.</span>fit(X, Energies)
regr_3<span style="color: #666666">.</span>fit(X, Energies)


y_1 <span style="color: #666666">=</span> regr_1<span style="color: #666666">.</span>predict(X)
y_2 <span style="color: #666666">=</span> regr_2<span style="color: #666666">.</span>predict(X)
y_3<span style="color: #666666">=</span>regr_3<span style="color: #666666">.</span>predict(X)
Masses[<span style="color: #BA2121">&#39;Eapprox&#39;</span>] <span style="color: #666666">=</span> y_3
<span style="color: #408080; font-style: italic"># Plot the results</span>
plt<span style="color: #666666">.</span>figure()
plt<span style="color: #666666">.</span>plot(A, Energies, color<span style="color: #666666">=</span><span style="color: #BA2121">&quot;blue&quot;</span>, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;Data&quot;</span>, linewidth<span style="color: #666666">=2</span>)
plt<span style="color: #666666">.</span>plot(A, y_1, color<span style="color: #666666">=</span><span style="color: #BA2121">&quot;red&quot;</span>, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;max_depth=5&quot;</span>, linewidth<span style="color: #666666">=2</span>)
plt<span style="color: #666666">.</span>plot(A, y_2, color<span style="color: #666666">=</span><span style="color: #BA2121">&quot;green&quot;</span>, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;max_depth=7&quot;</span>, linewidth<span style="color: #666666">=2</span>)
plt<span style="color: #666666">.</span>plot(A, y_3, color<span style="color: #666666">=</span><span style="color: #BA2121">&quot;m&quot;</span>, label<span style="color: #666666">=</span><span style="color: #BA2121">&quot;max_depth=9&quot;</span>, linewidth<span style="color: #666666">=2</span>)

plt<span style="color: #666666">.</span>xlabel(<span style="color: #BA2121">&quot;$A$&quot;</span>)
plt<span style="color: #666666">.</span>ylabel(<span style="color: #BA2121">&quot;$E$[MeV]&quot;</span>)
plt<span style="color: #666666">.</span>title(<span style="color: #BA2121">&quot;Decision Tree Regression&quot;</span>)
plt<span style="color: #666666">.</span>legend()
save_fig(<span style="color: #BA2121">&quot;Masses2016Trees&quot;</span>)
plt<span style="color: #666666">.</span>show()
<span style="color: #008000">print</span>(Masses)
<span style="color: #008000">print</span>(np<span style="color: #666666">.</span>mean( (Energies<span style="color: #666666">-</span>y_1)<span style="color: #666666">**2</span>))
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>
<h3 id="and-what-about-using-neural-networks" class="anchor">And what about using neural networks? </h3>
<p>The <b>seaborn</b> package allows us to visualize data in an efficient way. Note that we use <b>scikit-learn</b>'s multi-layer perceptron (or feed forward neural network) 
functionality.
</p>

<!-- code=python (!bc pycod) typeset with pygments style "default" -->
<div class="cell border-box-sizing code_cell rendered">
  <div class="input">
    <div class="inner_cell">
      <div class="input_area">
        <div class="highlight" style="background: #f8f8f8">
  <pre style="line-height: 125%;"><span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.neural_network</span> <span style="color: #008000; font-weight: bold">import</span> MLPRegressor
<span style="color: #008000; font-weight: bold">from</span> <span style="color: #0000FF; font-weight: bold">sklearn.metrics</span> <span style="color: #008000; font-weight: bold">import</span> accuracy_score
<span style="color: #008000; font-weight: bold">import</span> <span style="color: #0000FF; font-weight: bold">seaborn</span> <span style="color: #008000; font-weight: bold">as</span> <span style="color: #0000FF; font-weight: bold">sns</span>

X_train <span style="color: #666666">=</span> X
Y_train <span style="color: #666666">=</span> Energies
n_hidden_neurons <span style="color: #666666">=</span> <span style="color: #666666">100</span>
epochs <span style="color: #666666">=</span> <span style="color: #666666">100</span>
<span style="color: #408080; font-style: italic"># store models for later use</span>
eta_vals <span style="color: #666666">=</span> np<span style="color: #666666">.</span>logspace(<span style="color: #666666">-5</span>, <span style="color: #666666">1</span>, <span style="color: #666666">7</span>)
lmbd_vals <span style="color: #666666">=</span> np<span style="color: #666666">.</span>logspace(<span style="color: #666666">-5</span>, <span style="color: #666666">1</span>, <span style="color: #666666">7</span>)
<span style="color: #408080; font-style: italic"># store the models for later use</span>
DNN_scikit <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((<span style="color: #008000">len</span>(eta_vals), <span style="color: #008000">len</span>(lmbd_vals)), dtype<span style="color: #666666">=</span><span style="color: #008000">object</span>)
train_accuracy <span style="color: #666666">=</span> np<span style="color: #666666">.</span>zeros((<span style="color: #008000">len</span>(eta_vals), <span style="color: #008000">len</span>(lmbd_vals)))
sns<span style="color: #666666">.</span>set()
<span style="color: #008000; font-weight: bold">for</span> i, eta <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">enumerate</span>(eta_vals):
    <span style="color: #008000; font-weight: bold">for</span> j, lmbd <span style="color: #AA22FF; font-weight: bold">in</span> <span style="color: #008000">enumerate</span>(lmbd_vals):
        dnn <span style="color: #666666">=</span> MLPRegressor(hidden_layer_sizes<span style="color: #666666">=</span>(n_hidden_neurons), activation<span style="color: #666666">=</span><span style="color: #BA2121">&#39;logistic&#39;</span>,
                            alpha<span style="color: #666666">=</span>lmbd, learning_rate_init<span style="color: #666666">=</span>eta, max_iter<span style="color: #666666">=</span>epochs)
        dnn<span style="color: #666666">.</span>fit(X_train, Y_train)
        DNN_scikit[i][j] <span style="color: #666666">=</span> dnn
        train_accuracy[i][j] <span style="color: #666666">=</span> dnn<span style="color: #666666">.</span>score(X_train, Y_train)

fig, ax <span style="color: #666666">=</span> plt<span style="color: #666666">.</span>subplots(figsize <span style="color: #666666">=</span> (<span style="color: #666666">10</span>, <span style="color: #666666">10</span>))
sns<span style="color: #666666">.</span>heatmap(train_accuracy, annot<span style="color: #666666">=</span><span style="color: #008000; font-weight: bold">True</span>, ax<span style="color: #666666">=</span>ax, cmap<span style="color: #666666">=</span><span style="color: #BA2121">&quot;viridis&quot;</span>)
ax<span style="color: #666666">.</span>set_title(<span style="color: #BA2121">&quot;Training Accuracy&quot;</span>)
ax<span style="color: #666666">.</span>set_ylabel(<span style="color: #BA2121">&quot;$\eta$&quot;</span>)
ax<span style="color: #666666">.</span>set_xlabel(<span style="color: #BA2121">&quot;$\lambda$&quot;</span>)
plt<span style="color: #666666">.</span>show()
</pre>
</div>
      </div>
    </div>
  </div>
  <div class="output_wrapper">
    <div class="output">
      <div class="output_area">
        <div class="output_subarea output_stream output_stdout output_text">          
        </div>
      </div>
    </div>
  </div>
</div>


<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pagination">
<li><a href="._mlnuclear-bs039.html">&laquo;</a></li>
  <li><a href="._mlnuclear-bs000.html">1</a></li>
  <li><a href="">...</a></li>
  <li><a href="._mlnuclear-bs032.html">33</a></li>
  <li><a href="._mlnuclear-bs033.html">34</a></li>
  <li><a href="._mlnuclear-bs034.html">35</a></li>
  <li><a href="._mlnuclear-bs035.html">36</a></li>
  <li><a href="._mlnuclear-bs036.html">37</a></li>
  <li><a href="._mlnuclear-bs037.html">38</a></li>
  <li><a href="._mlnuclear-bs038.html">39</a></li>
  <li><a href="._mlnuclear-bs039.html">40</a></li>
  <li class="active"><a href="._mlnuclear-bs040.html">41</a></li>
  <li><a href="._mlnuclear-bs041.html">42</a></li>
  <li><a href="._mlnuclear-bs042.html">43</a></li>
  <li><a href="._mlnuclear-bs043.html">44</a></li>
  <li><a href="._mlnuclear-bs044.html">45</a></li>
  <li><a href="._mlnuclear-bs045.html">46</a></li>
  <li><a href="._mlnuclear-bs046.html">47</a></li>
  <li><a href="._mlnuclear-bs047.html">48</a></li>
  <li><a href="._mlnuclear-bs048.html">49</a></li>
  <li><a href="._mlnuclear-bs049.html">50</a></li>
  <li><a href="">...</a></li>
  <li><a href="._mlnuclear-bs187.html">188</a></li>
  <li><a href="._mlnuclear-bs041.html">&raquo;</a></li>
</ul>
<!-- ------------------- end of main content --------------- -->
</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<!-- Bootstrap footer
<footer>
<a href="https://..."><img width="250" align=right src="https://..."></a>
</footer>
-->
</body>
</html>

